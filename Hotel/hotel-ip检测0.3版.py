import os
import re
import requests
import time
import json
import concurrent.futures
import random
import threading
from datetime import datetime, timedelta
from urllib.parse import quote, unquote
import base64
from queue import Queue
import eventlet

# ===============================
# é…ç½®åŒº
# ===============================

# FOFA Cookie
FOFA_COOKIE = "isRedirectLang=1; is_mobile=pc; __fcd=DQVA3CHUNOEWDZUY01EE1FAF708C52E9; Hm_lvt_4275507ba9b9ea6b942c7a3f7" \
              "c66da90=1769490368; HMACCOUNT=79E7429D30B36B70; _ga=GA1.1.561856398.1769490368; befor_router=%2Fresult%3F" \
              "qbase64%3DImlwdHYvbGl2ZS96aF9jbi5qcyIgJiYgY291bnRyeT0iQ04iICYmIHByb3ZpbmNlOiAiYW5odWki%26page%3D5%26page" \
              "_size%3D20; fofa_token=eyJhbGciOiJIUzUxMiIsImtpZCI6Ik5XWTVZakF4TVRkalltSTJNRFZsWXpRM05EWXdaakF3TURVMlkyW" \
              "TNZemd3TUdRd1pUTmpZUT09IiwidHlwIjoiSldUIn0.eyJpZCI6MTE4MTAxMSwibWlkIjoxMDA3NDEyMzIsInVzZXJuYW1lIjoiT1Vfe" \
              "WFuZyIsInBhcmVudF9pZCI6MCwiZXhwIjoxNzcwMDk1MTk2fQ.Dgvo38VAYRzhoBjLlNdk9oAAwXczhGHjDALiJoleKcnMQDex9Mz6jDC" \
              "Ompl-Ay5abNuGjlLxF8A1fTYMgmXPsA; user=%7B%22id%22%3A1181011%2C%22mid%22%3A100741232%2C%22is_admin%22%3" \
              "Afalse%2C%22username%22%3A%22OU_yang%22%2C%22nickname%22%3A%22OU_yang%22%2C%22email%22%3A%222856364053%" \
              "40qq.com%22%2C%22avatar_medium%22%3A%22https%3A%2F%2Fnosec.org%2Fmissing.jpg%22%2C%22avatar_thumb%22%3A%" \
              "22https%3A%2F%2Fnosec.org%2Fmissing.jpg%22%2C%22key%22%3A%229495b90e65813ae0e9188e6a5928d1f1%22%2C%22cat" \
              "egory%22%3A%22user%22%2C%22rank_avatar%22%3A%22%22%2C%22rank_level%22%3A0%2C%22rank_name%22%3A%22%E6%B3%" \
              "A8%E5%86%8C%E7%94%A8%E6%88%B7%22%2C%22company_name%22%3A%22OU_yang%22%2C%22coins%22%3A0%2C%22can_pay_" \
              "coins%22%3A0%2C%22fofa_point%22%3A0%2C%22credits%22%3A1%2C%22expiration%22%3A%22-%22%2C%22login_at%22%" \
              "3A0%2C%22data_limit%22%3A%7B%22web_query%22%3A300%2C%22web_data%22%3A3000%2C%22api_query%22%3A0%2C%22" \
              "api_data%22%3A0%2C%22data%22%3A-1%2C%22query%22%3A-1%7D%2C%22expiration_notice%22%3Afalse%2C%22remain_" \
              "giveaway%22%3A1000%2C%22fpoint_upgrade%22%3Afalse%2C%22account_status%22%3A%22%22%2C%22parents_" \
              "id%22%3A0%2C%22parents_email%22%3A%22%22%2C%22parents_fpoint%22%3A0%2C%22created_at%22%3A%222026-01" \
              "-25%2000%3A00%3A00%22%7D; is_flag_login=1; baseShowChange=false; viewOneHundredData=false; _ga_9GWBD260" \
              "K9=GS2.1.s1769520942$o5$g1$t1769521320$j33$l0$h0; Hm_lpvt_4275507ba9b9ea6b942c7a3f7c66da90=1769521320"

# æœç´¢å…³é”®è¯ï¼ˆæŒ‰çœä»½æœç´¢ï¼‰
SEARCH_QUERIES = [
    '"iptv/live/zh_cn.js" && country="CN"',
    # '"iptv/live/zh_cn.js" && country="CN" && region="Anhui"',  # å®‰å¾½
    # '"iptv/live/zh_cn.js" && country="CN" && region="Beijing"',  # åŒ—äº¬
    # '"iptv/live/zh_cn.js" && country="CN" && region="Shanghai"',  # ä¸Šæµ·
    # '"iptv/live/zh_cn.js" && country="CN" && region="Jiangsu"',  # æ±Ÿè‹
    # '"iptv/live/zh_cn.js" && country="CN" && region="Zhejiang"',  # æµ™æ±Ÿ
    # '"iptv/live/zh_cn.js" && country="CN" && region="Fujian"',  # ç¦å»º
    # '"iptv/live/zh_cn.js" && country="CN" && region="Guangdong"',  # å¹¿ä¸œ
    # '"iptv/live/zh_cn.js" && country="CN" && region="Hunan"',  # æ¹–å—
    # '"iptv/live/zh_cn.js" && country="CN" && region="Hubei"',  # æ¹–åŒ—
    # '"iptv/live/zh_cn.js" && country="CN" && region="Henan"',  # æ²³å—
    # '"iptv/live/zh_cn.js" && country="CN" && region="Hebei"',  # æ²³åŒ—
    # '"iptv/live/zh_cn.js" && country="CN" && region="Shandong"',  # å±±ä¸œ
    # '"iptv/live/zh_cn.js" && country="CN" && region="Shanxi"',  # å±±è¥¿
    # '"iptv/live/zh_cn.js" && country="CN" && region="Shaanxi"',  # é™•è¥¿
    # '"iptv/live/zh_cn.js" && country="CN" && region="Sichuan"',  # å››å·
    # '"iptv/live/zh_cn.js" && country="CN" && region="Chongqing"',  # é‡åº†
    # '"iptv/live/zh_cn.js" && country="CN" && region="Liaoning"',  # è¾½å®
    # '"iptv/live/zh_cn.js" && country="CN" && region="Jilin"',  # å‰æ—
    # '"iptv/live/zh_cn.js" && country="CN" && region="Heilongjiang"',  # é»‘é¾™æ±Ÿ
    # '"iptv/live/zh_cn.js" && country="CN" && region="Jiangxi"',  # æ±Ÿè¥¿
    # '"iptv/live/zh_cn.js" && country="CN" && region="Guangxi"',  # å¹¿è¥¿
    # '"iptv/live/zh_cn.js" && country="CN" && region="Yunnan"',  # äº‘å—
    # '"iptv/live/zh_cn.js" && country="CN" && region="Guizhou"',  # è´µå·
    # '"iptv/live/zh_cn.js" && country="CN" && region="Gansu"',  # ç”˜è‚ƒ
    # '"iptv/live/zh_cn.js" && country="CN" && region="Ningxia"',  # å®å¤
    # '"iptv/live/zh_cn.js" && country="CN" && region="Qinghai"',  # é’æµ·
    # '"iptv/live/zh_cn.js" && country="CN" && region="Xinjiang"',  # æ–°ç–†
    # '"iptv/live/zh_cn.js" && country="CN" && region="Tianjin"',  # å¤©æ´¥
    # '"iptv/live/zh_cn.js" && country="CN" && region="Hainan"',  # æµ·å—
    # '"iptv/live/zh_cn.js" && country="CN" && region="Neimenggu"',  # å†…è’™å¤
    # '"iptv/live/zh_cn.js" && country="CN" && region="Xizang"',  # è¥¿è—
]

# IPå­˜å‚¨ç›®å½•
IP_DIR = "Hotel/ip"
if not os.path.exists(IP_DIR):
    os.makedirs(IP_DIR)

# æµ‹é€Ÿé˜ˆå€¼ (MB/s)
SPEED_THRESHOLD = 0.1

# User-Agentåˆ—è¡¨
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15"
]

# çœä»½å«è§†æ˜ å°„
PROVINCE_TV_MAP = {
    "åŒ—äº¬": "åŒ—äº¬å«è§†", "å¤©æ´¥": "å¤©æ´¥å«è§†", "æ²³åŒ—": "æ²³åŒ—å«è§†", "å±±è¥¿": "å±±è¥¿å«è§†", "å†…è’™å¤": "å†…è’™å¤å«è§†",
    "è¾½å®": "è¾½å®å«è§†", "å‰æ—": "å‰æ—å«è§†", "é»‘é¾™æ±Ÿ": "é»‘é¾™æ±Ÿå«è§†", "ä¸Šæµ·": "ä¸Šæµ·å«è§†", "æ±Ÿè‹": "æ±Ÿè‹å«è§†",
    "æµ™æ±Ÿ": "æµ™æ±Ÿå«è§†", "å®‰å¾½": "å®‰å¾½å«è§†", "ç¦å»º": "ä¸œå—å«è§†", "æ±Ÿè¥¿": "æ±Ÿè¥¿å«è§†", "å±±ä¸œ": "å±±ä¸œå«è§†",
    "æ²³å—": "æ²³å—å«è§†", "æ¹–åŒ—": "æ¹–åŒ—å«è§†", "æ¹–å—": "æ¹–å—å«è§†", "å¹¿ä¸œ": "å¹¿ä¸œå«è§†", "å¹¿è¥¿": "å¹¿è¥¿å«è§†",
    "æµ·å—": "æµ·å—å«è§†", "é‡åº†": "é‡åº†å«è§†", "å››å·": "å››å·å«è§†", "è´µå·": "è´µå·å«è§†", "äº‘å—": "äº‘å—å«è§†",
    "è¥¿è—": "è¥¿è—å«è§†", "é™•è¥¿": "é™•è¥¿å«è§†", "ç”˜è‚ƒ": "ç”˜è‚ƒå«è§†", "é’æµ·": "é’æµ·å«è§†", "å®å¤": "å®å¤å«è§†",
    "æ–°ç–†": "æ–°ç–†å«è§†",
}


# ===============================
# å·¥å…·å‡½æ•°
# ===============================

def get_random_headers():
    """è·å–éšæœºUser-Agentçš„headers"""
    return {
        "User-Agent": random.choice(USER_AGENTS),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "Cookie": FOFA_COOKIE
    }


def get_isp(ip):
    """IPè¿è¥å•†åˆ¤æ–­"""
    telecom_pattern = r"^(1\.|14\.|27\.|36\.|39\.|42\.|49\.|58\.|60\.|101\.|106\.|110\.|111\.|112\.|113\.|114\.|115\.|116\.|117\.|118\.|119\.|120\.|121\.|122\.|123\.|124\.|125\.|126\.|171\.|175\.|182\.|183\.|202\.|203\.|210\.|211\.|218\.|219\.|220\.|221\.|222\.)"
    unicom_pattern = r"^(42\.1[0-9]{0,2}|43\.|58\.|59\.|60\.|61\.|110\.|111\.|112\.|113\.|114\.|115\.|116\.|117\.|118\.|119\.|120\.|121\.|122\.|123\.|124\.|125\.|126\.|171\.8[0-9]|171\.9[0-9]|171\.1[0-9]{2}|175\.|182\.|183\.|210\.|211\.|218\.|219\.|220\.|221\.|222\.)"
    mobile_pattern = r"^(36\.|37\.|38\.|39\.1[0-9]{0,2}|42\.2|42\.3|47\.|106\.|111\.|112\.|113\.|114\.|115\.|116\.|117\.|118\.|119\.|120\.|121\.|122\.|123\.|124\.|125\.|126\.|134\.|135\.|136\.|137\.|138\.|139\.|150\.|151\.|152\.|157\.|158\.|159\.|170\.|178\.|182\.|183\.|184\.|187\.|188\.|189\.)"

    if re.match(telecom_pattern, ip):
        return "ç”µä¿¡"
    elif re.match(unicom_pattern, ip):
        return "è”é€š"
    elif re.match(mobile_pattern, ip):
        return "ç§»åŠ¨"
    else:
        return "æœªçŸ¥"


def get_ip_info(ip_port):
    """è·å–IPåœ°ç†ä¿¡æ¯"""
    try:
        ip = ip_port.split(":")[0]

        # ä½¿ç”¨IP-APIæŸ¥è¯¢
        try:
            response = requests.get(f"http://ip-api.com/json/{ip}?lang=zh-CN", timeout=5)
            if response.status_code == 200:
                data = response.json()
                if data.get("status") == "success":
                    province = data.get("regionName", "æœªçŸ¥")
                    isp = get_isp(ip)
                    return province, isp, ip_port
        except:
            pass

        return "æœªçŸ¥", "æœªçŸ¥", ip_port

    except Exception as e:
        return "æœªçŸ¥", "æœªçŸ¥", ip_port


def parse_ip_line(line):
    """è§£æIPè¡Œï¼Œæ”¯æŒæ ¼å¼ï¼šip:port$è¿è¥å•†å·²å­˜æ´»nå¤©"""
    line = line.strip()
    if not line or line.startswith('#'):
        return None, None, 0, None, None

    # åŒ¹é…IP:ç«¯å£æ ¼å¼
    ip_match = re.match(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d{1,5})', line)
    if not ip_match:
        return None, None, 0, None, None

    ip_port = ip_match.group(1)

    # å°è¯•è§£æå­˜æ´»å¤©æ•°
    days_match = re.search(r'å·²å­˜æ´»(\d+)å¤©', line)
    days = int(days_match.group(1)) if days_match else 0

    # å°è¯•è§£æè¿è¥å•†
    isp_match = re.search(r'\$([^$]+?)å·²å­˜æ´»', line)
    isp = isp_match.group(1).strip() if isp_match else ""

    # å°è¯•è§£ææœ€åæ›´æ–°æ—¥æœŸ
    date_match = re.search(r'æœ€åæ›´æ–°:(\d{4}-\d{2}-\d{2})', line)
    last_update = date_match.group(1) if date_match else None

    # å°è¯•è§£æé€Ÿåº¦
    speed_match = re.search(r'#é€Ÿåº¦:([\d.]+)MB/s', line)
    speed = float(speed_match.group(1)) if speed_match else 0.0

    return ip_port, isp, days, last_update, speed


def read_existing_ips(filepath):
    """è¯»å–ç°æœ‰æ–‡ä»¶å†…å®¹å¹¶è§£æ"""
    existing_ips = {}  # ip_port: (days, isp, last_update, speed)
    if os.path.exists(filepath):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                for line in f:
                    ip_port, isp, days, last_update, speed = parse_ip_line(line)
                    if ip_port:
                        existing_ips[ip_port] = (days, isp, last_update, speed)
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶ {filepath} å¤±è´¥: {e}")

    return existing_ips


def encode_query(query):
    """ç¼–ç æŸ¥è¯¢å­—ç¬¦ä¸²ä¸ºbase64"""
    return base64.b64encode(query.encode()).decode()


def generate_fofa_urls():
    """ç”ŸæˆFOFAæœç´¢URL"""
    urls = []
    pages = 2
    page_size = 30

    for query in SEARCH_QUERIES:
        encoded_query = encode_query(query)
        for page in range(1, pages + 1):
            url = f"https://fofa.info/result?qbase64={encoded_query}&page={page}&page_size={page_size}"
            urls.append(url)

    return urls


# ===============================
# çˆ¬å–å‡½æ•°
# ===============================

def crawl_fofa_with_cookie():
    """ä½¿ç”¨Cookieçˆ¬å–FOFAæ•°æ®"""
    urls = generate_fofa_urls()
    all_ips = set()
    session = requests.Session()

    print(f"ğŸ” å¼€å§‹çˆ¬å–FOFAï¼Œå…± {len(urls)} ä¸ªæœç´¢é¡µé¢")

    for i, url in enumerate(urls, 1):
        print(f"ğŸ“¡ æ­£åœ¨çˆ¬å–ç¬¬ {i}/{len(urls)} é¡µ: {url}")

        try:
            # éšæœºå»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(random.uniform(2, 5))

            # ä½¿ç”¨å¸¦Cookieçš„headers
            headers = get_random_headers()
            response = session.get(url, headers=headers, timeout=15)

            if response.status_code == 403 or "è®¿é—®é™åˆ¶" in response.text or "è¯·ç™»å½•" in response.text:
                print(f"âŒ ç¬¬ {i} é¡µè®¿é—®è¢«é™åˆ¶ï¼Œå¯èƒ½éœ€è¦é‡æ–°ç™»å½•")
                continue

            if response.status_code != 200:
                print(f"âŒ ç¬¬ {i} é¡µè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                continue

            # ä¿å­˜é¡µé¢å†…å®¹ç”¨äºåˆ†æ
            if i == 1:  # åªä¿å­˜ç¬¬ä¸€é¡µç”¨äºè°ƒè¯•
                with open("fofa_first_page.html", "w", encoding="utf-8") as f:
                    f.write(response.text)
                print("ğŸ’¾ å·²ä¿å­˜ç¬¬ä¸€é¡µHTMLåˆ° fofa_first_page.html")

            # å¤šç§æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…IP
            ip_patterns = [
                r'<a[^>]*href="[^"]*?//(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d{1,5})"',  # IP:ç«¯å£
                r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d{1,5})',  # é€šç”¨IP:ç«¯å£æ ¼å¼
                r'ip.*?(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}).*?port.*?(\d{1,5})',  # IPå’Œç«¯å£åˆ†å¼€
                r'host.*?(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}).*?port.*?(\d{1,5})'  # hostå’Œport
            ]

            page_ips = set()
            for pattern in ip_patterns:
                matches = re.findall(pattern, response.text, re.IGNORECASE)
                for match in matches:
                    if isinstance(match, tuple):
                        if len(match) == 2:
                            ip_port = f"{match[0]}:{match[1]}"
                        else:
                            continue
                    else:
                        ip_port = match

                    # éªŒè¯IPå’Œç«¯å£æ ¼å¼
                    ip_match = re.match(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}):(\d{1,5})', ip_port)
                    if ip_match:
                        # éªŒè¯IPåœ°å€çš„æ¯ä¸ªéƒ¨åˆ†
                        ip_parts = ip_match.group(1).split('.')
                        if all(0 <= int(part) <= 255 for part in ip_parts):
                            # éªŒè¯ç«¯å£
                            port = int(ip_match.group(2))
                            if 1 <= port <= 65535:
                                page_ips.add(ip_port)
                                print(f"âœ… æ‰¾åˆ°IP: {ip_port}")

            all_ips.update(page_ips)
            print(f"âœ… ç¬¬ {i} é¡µè·å–åˆ° {len(page_ips)} ä¸ªIPï¼Œå½“å‰æ€»æ•° {len(all_ips)}")

        except Exception as e:
            print(f"âŒ ç¬¬ {i} é¡µçˆ¬å–å¤±è´¥: {e}")

    print(f"ğŸ¯ FOFAçˆ¬å–å®Œæˆï¼Œæ€»å…±è·å–åˆ° {len(all_ips)} ä¸ªæœ‰æ•ˆIP")
    return all_ips


# ===============================
# IPå¯ç”¨æ€§éªŒè¯å’Œæµ‹é€Ÿå‡½æ•°ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
# ===============================

def test_ip_availability(ip_port):
    """æµ‹è¯•IPå¯ç”¨æ€§"""
    try:
        # æµ‹è¯•JSONæ¥å£
        json_url = f"http://{ip_port}/iptv/live/1000.json?key=txiptv"
        response = requests.get(json_url, timeout=5)

        if response.status_code == 200:
            try:
                data = response.json()
                if data.get("code") == 0 and "data" in data:
                    return True, data
            except:
                pass
        return False, None
    except:
        return False, None


def get_province_tv_url(ip_port, json_data, province_name):
    """è·å–çœä»½å«è§†URL"""
    try:
        tv_name = PROVINCE_TV_MAP.get(province_name)
        if not tv_name:
            return None

        for channel in json_data.get("data", []):
            if tv_name in channel.get("name", ""):
                url = channel.get("url", "")
                if url:
                    # æ„å»ºå®Œæ•´URL
                    if url.startswith("/"):
                        return f"http://{ip_port}{url}"
                    else:
                        return f"http://{ip_port}/{url}"
        return None
    except:
        return None


def test_channel_speed(channel_url, max_attempts=2):
    """æµ‹è¯•é¢‘é“é€Ÿåº¦ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
    best_speed = 0.0

    for attempt in range(max_attempts):
        try:
            # è·å–m3u8æ–‡ä»¶å†…å®¹
            response = requests.get(channel_url, timeout=3)
            if response.status_code != 200:
                if attempt < max_attempts - 1:
                    print(f"ç¬¬{attempt + 1}æ¬¡æµ‹é€Ÿ {channel_url}: HTTP {response.status_code}ï¼Œå°†é‡è¯•")
                continue

            lines = response.text.strip().split('\n')
            ts_lists = [line.split('/')[-1] for line in lines if line.startswith('#') == False and line.strip()]
            if not ts_lists:
                if attempt < max_attempts - 1:
                    print(f"ç¬¬{attempt + 1}æ¬¡æµ‹é€Ÿ {channel_url}: æ²¡æœ‰æ‰¾åˆ°TSåˆ—è¡¨ï¼Œå°†é‡è¯•")
                continue

            # è·å–TSæ–‡ä»¶çš„URL
            channel_url_t = channel_url.rstrip(channel_url.split('/')[-1])
            ts_url = channel_url_t + ts_lists[0]

            # æµ‹é€Ÿé€»è¾‘
            start_time = time.time()
            try:
                with eventlet.Timeout(5, False):
                    ts_response = requests.get(ts_url, timeout=6, stream=True)
                    if ts_response.status_code != 200:
                        if attempt < max_attempts - 1:
                            print(f"ç¬¬{attempt + 1}æ¬¡æµ‹é€Ÿ {channel_url}: TSæ–‡ä»¶HTTP {ts_response.status_code}ï¼Œå°†é‡è¯•")
                        continue

                    # è¯»å–éƒ¨åˆ†å†…å®¹è¿›è¡Œæµ‹é€Ÿ
                    content_length = 0
                    chunk_size = 1024 * 1024  # 1MB
                    for chunk in ts_response.iter_content(chunk_size=chunk_size):
                        if chunk:
                            content_length += len(chunk)
                            # åªè¯»å–1MBç”¨äºæµ‹é€Ÿ
                            if content_length >= chunk_size:
                                break

                    resp_time = time.time() - start_time

                    if content_length > 0 and resp_time > 0:
                        normalized_speed = content_length / resp_time / 1024 / 1024

                        # æ›´æ–°æœ€ä½³é€Ÿåº¦
                        if normalized_speed > best_speed:
                            best_speed = normalized_speed

                        # å¦‚æœé€Ÿåº¦åˆæ ¼ï¼Œä¸å†é‡è¯•
                        if normalized_speed > SPEED_THRESHOLD:
                            break
                        else:
                            if attempt < max_attempts - 1:
                                print(f"ç¬¬{attempt + 1}æ¬¡æµ‹é€Ÿ {channel_url}: {normalized_speed:.3f} MB/sï¼Œå°†é‡è¯•")
                    else:
                        if attempt < max_attempts - 1:
                            print(f"ç¬¬{attempt + 1}æ¬¡æµ‹é€Ÿ {channel_url}: è·å–å†…å®¹å¤±è´¥ï¼Œå°†é‡è¯•")
            except eventlet.Timeout:
                if attempt < max_attempts - 1:
                    print(f"ç¬¬{attempt + 1}æ¬¡æµ‹é€Ÿ {channel_url}: è¯·æ±‚è¶…æ—¶ï¼Œå°†é‡è¯•")
                continue
            except Exception as e:
                if attempt < max_attempts - 1:
                    print(f"ç¬¬{attempt + 1}æ¬¡æµ‹é€Ÿ {channel_url} å¤±è´¥: {str(e)}ï¼Œå°†é‡è¯•")
                continue

        except Exception as e:
            if attempt < max_attempts - 1:
                print(f"ç¬¬{attempt + 1}æ¬¡æµ‹é€Ÿ {channel_url} å¤„ç†å¤±è´¥: {str(e)}ï¼Œå°†é‡è¯•")
            continue

    return best_speed


def test_single_ip(ip_port, province_name):
    """æµ‹è¯•å•ä¸ªIPçš„å¯ç”¨æ€§å’Œé€Ÿåº¦"""
    try:
        # 1. æµ‹è¯•IPå¯ç”¨æ€§
        is_available, json_data = test_ip_availability(ip_port)
        if not is_available:
            return 0.0, False

        # 2. è·å–çœä»½å«è§†URL
        channel_url = get_province_tv_url(ip_port, json_data, province_name)
        if not channel_url:
            return 0.0, False

        # 3. æµ‹é€Ÿ
        speed = test_channel_speed(channel_url)
        return speed, speed > SPEED_THRESHOLD

    except Exception as e:
        return 0.0, False


def speed_test_ips(ip_list, province_name):
    """å¤šçº¿ç¨‹æµ‹é€ŸIPåˆ—è¡¨ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
    results = []
    checked = [0]
    total_count = len(ip_list)

    def show_progress():
        """æ˜¾ç¤ºè¿›åº¦"""
        while checked[0] < total_count:
            numberx = checked[0] / total_count * 100
            print(f"å·²æµ‹è¯•{checked[0]}/{total_count}ï¼Œå¯ç”¨é¢‘é“:{len(results)}ä¸ªï¼Œè¿›åº¦:{numberx:.2f}%")
            time.sleep(5)

    def worker():
        """å·¥ä½œçº¿ç¨‹"""
        while True:
            try:
                # ä»é˜Ÿåˆ—ä¸­è·å–ä»»åŠ¡
                with task_queue_lock:
                    if not task_queue:
                        break
                    ip_info = task_queue.pop(0)

                ip_port = ip_info[0]
                speed, is_usable = test_single_ip(ip_port, province_name)

                if is_usable:
                    result = (ip_info[0], ip_info[1], ip_info[2], speed)
                    results.append(result)
                    print(f"âœ“ {ip_port}: {speed:.3f} MB/s")
                else:
                    print(f"Ã— {ip_port}: {speed:.3f} MB/s")

                checked[0] += 1
            except Exception as e:
                checked[0] += 1
                print(f"å¤„ç† {ip_info[0]} æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—
    task_queue = ip_list.copy()
    task_queue_lock = threading.Lock()

    # å¯åŠ¨è¿›åº¦æ˜¾ç¤ºçº¿ç¨‹
    progress_thread = threading.Thread(target=show_progress, daemon=True)
    progress_thread.start()

    # åˆ›å»ºå·¥ä½œçº¿ç¨‹
    threads = []
    for _ in range(min(10, len(ip_list))):
        thread = threading.Thread(target=worker)
        thread.daemon = True
        thread.start()
        threads.append(thread)

    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for thread in threads:
        thread.join()

    # æŒ‰é€Ÿåº¦æ’åº
    results.sort(key=lambda x: x[3], reverse=True)
    return results


# ===============================
# æ–‡ä»¶ç®¡ç†å’Œæ›´æ–°å‡½æ•°
# ===============================
def calculate_days_between(date_str1, date_str2):
    """è®¡ç®—ä¸¤ä¸ªæ—¥æœŸå­—ç¬¦ä¸²ä¹‹é—´çš„å¤©æ•°å·®"""
    try:
        date1 = datetime.strptime(date_str1, "%Y-%m-%d")
        date2 = datetime.strptime(date_str2, "%Y-%m-%d")
        return (date2 - date1).days
    except:
        return 0



def update_ip_file(filepath, new_usable_ips):
    """æ›´æ–°IPæ–‡ä»¶ - ä¿®å¤å­˜æ´»å¤©æ•°è®¡ç®—"""
    try:
        existing_ips = read_existing_ips(filepath)
        current_date = datetime.now().strftime("%Y-%m-%d")

        updated_ips = {}
        for ip_port, (days, isp, last_update, old_speed) in existing_ips.items():
            is_still_usable = any(ip[0] == ip_port for ip in new_usable_ips)

            if is_still_usable:
                if not isp:
                    ip = ip_port.split(":")[0]
                    isp = get_isp(ip)

                if last_update:
                    days_diff = calculate_days_between(last_update, current_date)
                    if days_diff > 0:
                        new_days = days + days_diff
                    else:
                        new_days = days
                else:
                    new_days = 1

                # è·å–æ–°çš„é€Ÿåº¦
                new_speed = old_speed
                for ip_info in new_usable_ips:
                    if ip_info[0] == ip_port:
                        new_speed = ip_info[3]
                        break

                updated_ips[ip_port] = (new_days, isp, current_date, new_speed)
            elif days > 0:
                updated_ips[ip_port] = (days, isp, last_update, old_speed)

        for ip_info in new_usable_ips:
            ip_port, isp, old_days, speed = ip_info
            if ip_port not in updated_ips:
                if not isp:
                    ip = ip_port.split(":")[0]
                    isp = get_isp(ip)
                updated_ips[ip_port] = (1, isp, current_date, speed)

        if not updated_ips:
            if os.path.exists(filepath):
                os.remove(filepath)
            print(f"ğŸ—‘ï¸ åˆ é™¤ç©ºæ–‡ä»¶: {os.path.basename(filepath)}")
            return

        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"# æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"# æµ‹é€Ÿé˜ˆå€¼: {SPEED_THRESHOLD} MB/s\n")
            f.write("# æ ¼å¼: IP:ç«¯å£$è¿è¥å•†å·²å­˜æ´»nå¤©#æœ€åæ›´æ–°:YYYY-MM-DD#é€Ÿåº¦\n")
            f.write("=" * 50 + "\n")

            sorted_ips = sorted(updated_ips.items(), key=lambda x: x[1][0], reverse=True)

            for ip_port, (days, isp, last_update, speed) in sorted_ips:
                speed_info = f"#é€Ÿåº¦:{speed:.3f}MB/s" if speed > 0 else ""
                f.write(f"{ip_port}${isp}å·²å­˜æ´»{days}å¤©#æœ€åæ›´æ–°:{last_update}{speed_info}\n")

        print(f"ğŸ’¾ å·²æ›´æ–° {os.path.basename(filepath)}ï¼Œæœ‰æ•ˆIP: {len(updated_ips)} ä¸ª")

    except Exception as e:
        print(f"âŒ æ›´æ–°æ–‡ä»¶ {filepath} å¤±è´¥: {e}")


def validate_existing_ips():
    """éªŒè¯ç°æœ‰IPæ–‡ä»¶ä¸­çš„IP"""
    print("ğŸ” å¼€å§‹éªŒè¯ç°æœ‰IPæ–‡ä»¶...")

    for filename in os.listdir(IP_DIR):
        if filename.endswith('.txt') and filename != "ip_summary.txt":
            filepath = os.path.join(IP_DIR, filename)

            match = re.match(r'(.+?)(ç”µä¿¡|è”é€š|ç§»åŠ¨|æœªçŸ¥)\.txt', filename)
            if not match:
                continue

            province = match.group(1)
            isp = match.group(2)

            print(f"ğŸ“‹ éªŒè¯æ–‡ä»¶: {filename} (çœä»½: {province}, è¿è¥å•†: {isp})")

            existing_ips = read_existing_ips(filepath)
            if not existing_ips:
                print(f"âš ï¸ æ–‡ä»¶ {filename} ä¸ºç©ºï¼Œè·³è¿‡éªŒè¯")
                continue

            ip_list = []
            for ip_port, (days, isp_val, last_update, speed) in existing_ips.items():
                ip_list.append((ip_port, isp_val, days))

            usable_ips = speed_test_ips(ip_list, province)
            update_ip_file(filepath, usable_ips)

    print("âœ… ç°æœ‰IPéªŒè¯å®Œæˆ")


def process_new_ips(new_ips):
    """å¤„ç†æ–°è·å–çš„IP - ä¿®å¤è¿è¥å•†è·å–"""
    if not new_ips:
        print("âš ï¸ æ²¡æœ‰è·å–åˆ°æ–°IP")
        return

    print(f"ğŸ”§ å¼€å§‹å¤„ç† {len(new_ips)} ä¸ªæ–°IP...")

    # è·å–IPä¿¡æ¯
    province_isp_dict = {}

    # ä½¿ç”¨çº¿ç¨‹æ± è·å–IPä¿¡æ¯
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        future_to_ip = {executor.submit(get_ip_info, ip): ip for ip in new_ips}

        for future in concurrent.futures.as_completed(future_to_ip):
            province, isp, ip_port = future.result()

            # ç¡®ä¿çœä»½å’Œè¿è¥å•†ä¸ä¸ºç©º
            if not province or province == "æœªçŸ¥":
                province = "å…¶ä»–"
            else:
                # æ¸…ç†çœä»½åç§°
                province = province.replace("çœ", "").replace("å¸‚", "").replace("è‡ªæ²»åŒº", "").replace("ç‰¹åˆ«è¡Œæ”¿åŒº", "").strip()
                if not province:
                    province = "å…¶ä»–"

            if not isp or isp == "æœªçŸ¥":
                ip = ip_port.split(":")[0]
                isp = get_isp(ip)

            fname = f"{province}{isp}.txt"
            province_isp_dict.setdefault(fname, []).append((ip_port, isp, 0))  # æ–°IPå­˜æ´»å¤©æ•°ä¸º0

    # æµ‹è¯•å¹¶ä¿å­˜æ–°IP
    for fname, ip_list in province_isp_dict.items():
        filepath = os.path.join(IP_DIR, fname)

        # ä»æ–‡ä»¶åæå–çœä»½
        match = re.match(r'(.+?)(ç”µä¿¡|è”é€š|ç§»åŠ¨|æœªçŸ¥)\.txt', fname)
        province = match.group(1) if match else "å…¶ä»–"

        print(f"ğŸ§ª æµ‹è¯• {fname} ä¸­çš„ {len(ip_list)} ä¸ªæ–°IP...")
        usable_ips = speed_test_ips(ip_list, province)

        if usable_ips:
            update_ip_file(filepath, usable_ips)
        else:
            print(f"âš ï¸ {fname} ä¸­æ²¡æœ‰å¯ç”¨çš„æ–°IP")

    print("âœ… æ–°IPå¤„ç†å®Œæˆ")


# ===============================
# ä¸»å‡½æ•°
# ===============================

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸŒ FOFA IPåœ°å€æŠ“å–ä¸éªŒè¯å·¥å…·")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {IP_DIR}")
    print(f"âš¡ æµ‹é€Ÿé˜ˆå€¼: {SPEED_THRESHOLD} MB/s")
    print("=" * 60)

    # ç¬¬ä¸€é˜¶æ®µï¼šéªŒè¯ç°æœ‰IP
    validate_existing_ips()

    # ç¬¬äºŒé˜¶æ®µï¼šçˆ¬å–æ–°IP
    print("\nğŸš€ å¼€å§‹çˆ¬å–FOFAæ–°IP...")
    new_ips = crawl_fofa_with_cookie()

    if new_ips:
        # å¤„ç†æ–°IP
        process_new_ips(new_ips)
    else:
        print("âŒ æ²¡æœ‰è·å–åˆ°æ–°IP")

    print("\n" + "=" * 60)
    print("ğŸ‰ ä»»åŠ¡å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    # å®‰è£…ä¾èµ–: pip install eventlet
    main()
