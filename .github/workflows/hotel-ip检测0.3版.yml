name: hotel-ipæ£€æµ‹0.3ç‰ˆ
on:
 # schedule:
 #   - cron: 0 */6 * * *
 workflow_dispatch:

jobs:
  run-script:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v2
  
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.x

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests eventlet
        pip install python-dotenv
        
    - name: hotel-ipæ£€æµ‹0.3ç‰ˆ
      run: |
       python << 'EOF'
       import os
       import re
       import requests
       import time
       import json
       import concurrent.futures
       import random
       import threading
       from datetime import datetime, timedelta
       from urllib.parse import quote, unquote
       import base64
       from queue import Queue
       import eventlet
       import sys
       import configparser
       
       # å¢žåŠ é€’å½’æ·±åº¦é™åˆ¶
       sys.setrecursionlimit(100)
       
       # ===============================
       # é…ç½®åŒº - ä»Žé…ç½®æ–‡ä»¶è¯»å–
       # ===============================
       
       # èŽ·å–è„šæœ¬æ‰€åœ¨ç›®å½•
       SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
       
       # é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆä¸Žè„šæœ¬åŒç›®å½•ï¼‰
       CONFIG_FILE = os.path.join(SCRIPT_DIR, "fofa_config.ini")
       COOKIE_FILE = os.path.join(SCRIPT_DIR, "cookie.txt")
       
       # IPå­˜å‚¨ç›®å½•
       IP_DIR = "Hotel/ip"
       if not os.path.exists(IP_DIR):
           os.makedirs(IP_DIR)
       
       # é¢‘é“æ–‡ä»¶è¾“å‡ºç›®å½•
       CHANNEL_DIR = "Hotel"
       if not os.path.exists(CHANNEL_DIR):
           os.makedirs(CHANNEL_DIR)
       
       # æµ‹é€Ÿé˜ˆå€¼ (MB/s)
       SPEED_THRESHOLD = 0.1
       
       # User-Agentåˆ—è¡¨
       USER_AGENTS = [
           "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
           "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
           "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
           "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15"
       ]
       
       def load_config():
           """ä»Žé…ç½®æ–‡ä»¶åŠ è½½FOFAé…ç½®"""
           config = configparser.ConfigParser()
           
           # é»˜è®¤é…ç½®
           default_config = {
               'fofa': {
                   'email_base64': '',  # Base64ç¼–ç çš„é‚®ç®±
                   'api_key_base64': '',  # Base64ç¼–ç çš„API KEY
               },
               'settings': {
                   'speed_threshold': '0.1',
                   'max_workers': '5',
                   'timeout': '10'
               }
           }
           
           # å¦‚æžœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤é…ç½®
           if not os.path.exists(CONFIG_FILE):
               config.read_dict(default_config)
               with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
                   config.write(f)
               print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå·²åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: {CONFIG_FILE}")
               print("ðŸ’¡ è¯·ç¼–è¾‘é…ç½®æ–‡ä»¶å¹¶è®¾ç½®Base64ç¼–ç çš„FOFAé‚®ç®±å’ŒAPI KEY")
               return None
           
           # è¯»å–çŽ°æœ‰é…ç½®
           config.read(CONFIG_FILE, encoding='utf-8')
           
           return config
       
       def decode_base64(encoded_str):
           """è§£ç Base64å­—ç¬¦ä¸²"""
           try:
               if encoded_str:
                   return base64.b64decode(encoded_str).decode('utf-8')
               return ""
           except:
               return ""
       
       def get_fofa_credentials():
           """èŽ·å–FOFAè®¤è¯ä¿¡æ¯"""
           config = load_config()
           if not config:
               return "", ""
           
           # èŽ·å–Base64ç¼–ç çš„é‚®ç®±å’ŒAPI KEY
           email_base64 = config.get('fofa', 'email_base64', fallback='')
           api_key_base64 = config.get('fofa', 'api_key_base64', fallback='')
           
           # è§£ç 
           email = decode_base64(email_base64)
           api_key = decode_base64(api_key_base64)
           
           return email, api_key
       
       def get_fofa_cookie():
           """ä»Žcookie.txtæ–‡ä»¶è¯»å–FOFA Cookie"""
           if os.path.exists(COOKIE_FILE):
               try:
                   with open(COOKIE_FILE, 'r', encoding='utf-8') as f:
                       cookie_content = f.read().strip()
                       if cookie_content:
                           print("âœ… å·²ä»Žcookie.txtåŠ è½½Cookie")
                           return cookie_content
               except Exception as e:
                   print(f"âŒ è¯»å–cookie.txtå¤±è´¥: {e}")
           
           print("âš ï¸ cookie.txtæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º")
           return ""
       
       def get_fofa_auth():
           """ç”ŸæˆFOFA APIè®¤è¯å¤´"""
           email, api_key = get_fofa_credentials()
           if email and api_key:
               auth_str = f"{email}:{api_key}"
               return base64.b64encode(auth_str.encode()).decode()
           return ""
       
       # æœç´¢å…³é”®è¯
       SEARCH_QUERIES = [
           '"iptv/live/zh_cn.js" && country="CN"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Anhui"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Beijing"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Shanghai"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Jiangsu"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Zhejiang"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Fujian"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Guangdong"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Hunan"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Hubei"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Henan"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Hebei"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Shandong"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Shanxi"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Shaanxi"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Sichuan"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Chongqing"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Liaoning"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Jilin"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Heilongjiang"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Jiangxi"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Guangxi"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Yunnan"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Guizhou"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Gansu"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Ningxia"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Qinghai"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Xinjiang"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Tianjin"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Hainan"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Neimenggu"',
           # '"iptv/live/zh_cn.js" && country="CN" && region="Xizang"',
       ]
       
       # é¢‘é“åˆ†ç±»å®šä¹‰
       CHANNEL_CATEGORIES = {
           "å¤®è§†é¢‘é“": [
               "CCTV1", "CCTV2", "CCTV3", "CCTV4", "CCTV4æ¬§æ´²", "CCTV4ç¾Žæ´²", "CCTV5", "CCTV5+", "CCTV6", "CCTV7",
               "CCTV8", "CCTV9", "CCTV10", "CCTV11", "CCTV12", "CCTV13", "CCTV14", "CCTV15", "CCTV16", "CCTV17",
               "å…µå™¨ç§‘æŠ€", "é£Žäº‘éŸ³ä¹", "é£Žäº‘è¶³çƒ", "é£Žäº‘å‰§åœº", "æ€€æ—§å‰§åœº", "ç¬¬ä¸€å‰§åœº", "å¥³æ€§æ—¶å°š", "ä¸–ç•Œåœ°ç†", "å¤®è§†å°çƒ", "é«˜å°”å¤«ç½‘çƒ",
               "å¤®è§†æ–‡åŒ–ç²¾å“", "å«ç”Ÿå¥åº·", "ç”µè§†æŒ‡å—", "è€æ•…äº‹", "ä¸­å­¦ç”Ÿ", "å‘çŽ°ä¹‹æ—…", "ä¹¦æ³•é¢‘é“", "å›½å­¦é¢‘é“", "çŽ¯çƒå¥‡è§‚",
               "CETV1", "CETV2", "CETV3", "CETV4", "æ—©æœŸæ•™è‚²", "CGTNçºªå½•",
           ],
           "å«è§†é¢‘é“": [
               "é‡æ¸©ç»å…¸", "æ¹–å—å«è§†", "æµ™æ±Ÿå«è§†", "æ±Ÿè‹å«è§†", "ä¸œæ–¹å«è§†", "æ·±åœ³å«è§†", "åŒ—äº¬å«è§†", "å¹¿ä¸œå«è§†", "å¹¿è¥¿å«è§†", "ä¸œå—å«è§†", "æµ·å—å«è§†",
               "æ²³åŒ—å«è§†", "æ²³å—å«è§†", "æ¹–åŒ—å«è§†", "æ±Ÿè¥¿å«è§†", "å››å·å«è§†", "é‡åº†å«è§†", "è´µå·žå«è§†", "äº‘å—å«è§†", "å¤©æ´¥å«è§†", "å®‰å¾½å«è§†", "åŽ¦é—¨å«è§†",
               "å±±ä¸œå«è§†", "è¾½å®å«è§†", "é»‘é¾™æ±Ÿå«è§†", "å‰æž—å«è§†", "å†…è’™å¤å«è§†", "å®å¤å«è§†", "å±±è¥¿å«è§†", "é™•è¥¿å«è§†", "ç”˜è‚ƒå«è§†", "é’æµ·å«è§†",
               "æ–°ç–†å«è§†", "è¥¿è—å«è§†", "ä¸‰æ²™å«è§†", "å…µå›¢å«è§†", "å»¶è¾¹å«è§†", "å®‰å¤šå«è§†", "åº·å·´å«è§†", "å†œæž—å«è§†", "å±±ä¸œæ•™è‚²å«è§†",
           ],
           "æ•°å­—é¢‘é“": [
               "CHCåŠ¨ä½œç”µå½±", "CHCå®¶åº­å½±é™¢", "CHCå½±è¿·ç”µå½±", "æ·˜ç”µå½±", "æ·˜ç²¾å½©", "æ·˜å‰§åœº", "æ·˜4K", "æ·˜å¨±ä¹", "æ·˜BABY", 
               "æ·˜èŒå® ", "æµ·çœ‹å¤§ç‰‡", "ç»å…¸ç”µå½±", "ç²¾å½©å½±è§†", "å–œå‰§å½±é™¢", "åŠ¨ä½œå½±é™¢", "ç²¾å“å‰§åœº", "IPTVæˆæ›²", "æ±‚ç´¢çºªå½•", "æ±‚ç´¢ç§‘å­¦", "æ³•åˆ¶å¤©åœ°",
               "æ±‚ç´¢ç”Ÿæ´»", "æ±‚ç´¢åŠ¨ç‰©", "çºªå®žäººæ–‡", "é‡‘é¹°çºªå®ž", "çºªå®žç§‘æ•™", "ç›å½©é’å°‘", "ç›å½©ç«žæŠ€", "ç›å½©ç¯®çƒ", "ç›å½©å¹¿åœºèˆž", "é­…åŠ›è¶³çƒ", "äº”æ˜Ÿä½“è‚²", "ä½“è‚²èµ›äº‹",
               "åŠ²çˆ†ä½“è‚²", "å¿«ä¹åž‚é’“", "å››æµ·é’“é±¼", "èŒ¶é¢‘é“", "å…ˆé”‹ä¹’ç¾½", "å¤©å…ƒå›´æ£‹", "æ±½æ‘©", "è½¦è¿·é¢‘é“", "æ¢¨å›­é¢‘é“", "æ–‡ç‰©å®åº“", "æ­¦æœ¯ä¸–ç•Œ",
               "ä¹æ¸¸", "ç”Ÿæ´»æ—¶å°š", "éƒ½å¸‚å‰§åœº", "æ¬¢ç¬‘å‰§åœº", "é‡‘è‰²å­¦å ‚", "åŠ¨æ¼«ç§€åœº", "æ–°åŠ¨æ¼«", "é‡‘é¹°å¡é€š", "ä¼˜æ¼«å¡é€š", "å“ˆå“ˆç‚«åŠ¨", "å˜‰ä½³å¡é€š", 
               "ä¼˜ä¼˜å®è´", "ä¸­å›½äº¤é€š", "ä¸­å›½å¤©æ°”", "ç½‘ç»œæ£‹ç‰Œ", 
           ],
           "æ¸¯æ¾³å°é¢‘é“": [
               "å‡¤å‡°å«è§†ä¸­æ–‡å°", "å‡¤å‡°å«è§†èµ„è®¯å°", "å‡¤å‡°å«è§†é¦™æ¸¯å°", "å‡¤å‡°å«è§†ç”µå½±å°", "é¾™ç¥¥æ—¶ä»£", "æ˜Ÿç©ºå«è§†", "CHANNEL[V]", "", "", "", "", "", "", "", "",
           ],
           "å®‰å¾½é¢‘é“": [
               "å®‰å¾½å½±è§†", "å®‰å¾½ç»æµŽç”Ÿæ´»", "å®‰å¾½å…¬å…±", "å®‰å¾½ç»¼è‰ºä½“è‚²", "å®‰å¾½å†œä¸šç§‘æ•™", "é˜œé˜³å…¬å…±é¢‘é“", "é©¬éžå±±æ–°é—»ç»¼åˆ", "é©¬éžå±±å…¬å…±", "", "", "", "çŽ¯çƒå¥‡è§‚",
               "ä¸´æ³‰ä¸€å°", "", "", "", "", "", "", "",
               "", "", "", "", "", "", "", "", "", "", "",
           ],
           "åŒ—äº¬é¢‘é“": [
               "åŒ—äº¬çºªå®žç§‘æ•™", "", "", "", "", "", "", "", "", "åŒ—äº¬å¡é…·å°‘å„¿", 
           ],
           "ä¸Šæµ·é¢‘é“": [
               "æ–°é—»ç»¼åˆ", "éƒ½å¸‚é¢‘é“", "ä¸œæ–¹å½±è§†", "çºªå®žäººæ–‡", "ç¬¬ä¸€è´¢ç»", "äº”æ˜Ÿä½“è‚²", "ä¸œæ–¹è´¢ç»", "ICSé¢‘é“", "ä¸Šæµ·æ•™è‚²å°", "ä¸ƒå½©æˆå‰§", "æ³•æ²»å¤©åœ°", "é‡‘è‰²å­¦å ‚",
               "åŠ¨æ¼«ç§€åœº", "æ¬¢ç¬‘å‰§åœº4K", "ç”Ÿæ´»æ—¶å°š", "", "", "", "", "",
               "", "", "", "", "", "", "", "", "", "", "",
           ],
           "æ¹–å—é¢‘é“": [
               "æ¹–å—å›½é™…", "æ¹–å—ç”µå½±", "æ¹–å—ç”µè§†å‰§", "æ¹–å—ç»è§†", "æ¹–å—å¨±ä¹", "æ¹–å—å…¬å…±", "æ¹–å—éƒ½å¸‚", "æ¹–å—æ•™è‚²", "èŠ’æžœäº’å¨±", "é•¿æ²™æ–°é—»", "é•¿æ²™æ”¿æ³•", "é•¿æ²™å½±è§†", "é•¿æ²™å¥³æ€§", "",
               "ç›Šé˜³å…¬å…±", "æŠ—æˆ˜å‰§åœº", "å¤è£…å‰§åœº", "é«˜æ¸…é™¢çº¿", "å…ˆé”‹å…µç¾½", "æœ›åŸŽç»¼åˆ", "èŠ±é¼“æˆ", "",
               "", "", "", "", "", "", "", "", "", "", "",
           ],
           "æ¹–åŒ—é¢‘é“": [
               "æ¹–åŒ—ç»¼åˆ", "æ¹–åŒ—å½±è§†", "æ¹–åŒ—ç”Ÿæ´»", "æ¹–åŒ—æ•™è‚²", "æ¹–åŒ—ç»è§†", "è†å·žæ–°é—»", "è†å·žåž„ä¸Š", "", "", "", "", "", "", "", "", "",
           ],
           "æ²³åŒ—é¢‘é“": [
               "æ²³åŒ—å½±è§†å‰§", "æ²³åŒ—éƒ½å¸‚", "æ²³åŒ—ç»æµŽ", "æ²³åŒ—å…¬å…±", "æ²³åŒ—å°‘å„¿ç§‘æ•™", "æ²³åŒ—ä¸‰å†œ", "è¡¡æ°´æ–°é—»", "è¡¡æ°´å…¬å…±", "", "", "", "", "", "",
           ],
           "å±±ä¸œé¢‘é“": [
               "å±±ä¸œç»¼è‰º", "å±±ä¸œå½±è§†", "å±±ä¸œé½é²", "å±±ä¸œå†œç§‘", "å±±ä¸œä½“è‚²", "å±±ä¸œç”Ÿæ´»", "å±±ä¸œå°‘å„¿", "çƒŸå°æ–°é—»", "å±±ä¸œæ•™è‚²", "ä¸´æ²‚å¯¼è§†", "ä¸´æ²‚å›¾æ–‡", "ä¸´æ²‚ç»¼åˆ", "ä¸´æ²‚å†œç§‘", "å…°é™µå¯¼è§†", "å…°é™µå…¬å…±", "å…°é™µç»¼åˆ",
           ],
           "å¹¿ä¸œé¢‘é“": [
               "å¹¿ä¸œå½±è§†", "", "", "", "", "", "å¹¿ä¸œç§‘æ•™", "å¹¿ä¸œä½“è‚²", "å¹¿å·žæ–°é—»", "å¹¿ä¸œç æ±Ÿ", "æ·±åœ³éƒ½å¸‚", "æ·±åœ³å°‘å„¿", "å˜‰ä½³å¡é€š", "èŒ‚åç»¼åˆ", "", "", "",
           ],
           "å¹¿è¥¿é¢‘é“": [
               "å¹¿è¥¿å½±è§†", "å¹¿è¥¿ç»¼è‰º", "å¹¿è¥¿éƒ½å¸‚", "å¹¿è¥¿æ–°é—»", "å¹¿è¥¿ç§»åŠ¨", "å¹¿è¥¿ç§‘æŠ€", "ç²¾å½©å½±è§†", "å¹³å—å°", "å—å®å½±è§†", "çŽ‰æž—æ–°é—»ç»¼åˆ", "", "", "", "", "", "", "",
           ],
           "å››å·é¢‘é“": [
               "å››å·æ–°é—»", "å››å·æ–‡åŒ–æ—…æ¸¸", "å››å·å½±è§†æ–‡è‰º", "å³¨çœ‰ç”µå½±", "ç†ŠçŒ«å½±é™¢", "å¹¿å…ƒç»¼åˆ", "å¹¿å…ƒå…¬å…±", "å››å·å«è§†-ä¹¡æ‘å…¬å…±", "è“¬å®‰ç”µè§†å°", "", "", "", "", "", "", "", "é‡‘ç†ŠçŒ«å¡é€š",
           ],
           "é™•è¥¿é¢‘é“": [
               "", "", "", "", "", "", "", "", "ä¸‰é—¨å³¡æ–°é—»ç»¼åˆ", "çµå®æ–°é—»ç»¼åˆ", "", "", "", "", "", "", "",
           ],    
           "æµ™æ±Ÿé¢‘é“": [
               "æµ™æ±Ÿæ–°é—»", "æ­å·žå½±è§†", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
           ], 
           "å‰æž—é¢‘é“": [
               "å‰æž—å½±è§†", "å‰æž—éƒ½å¸‚", "å‰æž—ä¹¡æ‘", "å‰æž—æ•™è‚²", "å‰æž—ç»¼è‰º", "å‰æž—ç”Ÿæ´»", "", "", "é•¿å½±é¢‘é“", "æ¾åŽŸå…¬å…±", "æ¾åŽŸ", "", "", "", "", "", "",
           ],
           "æ–°ç–†é¢‘é“": [
               "æ–°ç–†2", "æ–°ç–†3", "æ–°ç–†4", "æ–°ç–†5", "æ–°ç–†6", "æ–°ç–†7", "æ–°ç–†8", "æ–°ç–†9", "", "", "", "", "", "", "", "", "",
           ],
           "å…¶ä»–é¢‘é“": []
       }
       
       # ç‰¹æ®Šç¬¦å·æ˜ å°„
       SPECIAL_SYMBOLS = ["HD", "LT", "XF", "-", "_", " ", ".", "Â·", "é«˜æ¸…", "æ ‡æ¸…", "è¶…æ¸…", "H265", "4K", "FHD", "HDTV"]
       
       # é¢‘é“åç§°æ˜ å°„
       CHANNEL_MAPPING = {
           "CCTV1": ["CCTV1", "CCTV-1", "CCTV1ç»¼åˆ", "CCTV1é«˜æ¸…", "CCTV1HD", "cctv1", "ä¸­å¤®1å°", "sCCTV1-ç»¼åˆ", "CCTV01"],
           "CCTV2": ["CCTV2", "CCTV-2", "CCTV2è´¢ç»", "CCTV2é«˜æ¸…", "CCTV2HD", "cctv2", "ä¸­å¤®2å°", "aCCTV2", "sCCTV2-è´¢ç»", "CCTV02"],
           "CCTV3": ["CCTV3", "CCTV-3", "CCTV3ç»¼è‰º", "CCTV3é«˜æ¸…", "CCTV3HD", "cctv3", "ä¸­å¤®3å°", "acctv3", "sCCTV3-ç»¼è‰º", "CCTV03"],
           "CCTV4": ["CCTV4", "CCTV-4", "CCTV4ä¸­æ–‡å›½é™…", "CCTV4é«˜æ¸…", "CCTV4HD", "cctv4", "ä¸­å¤®4å°", "aCCTV4", "sCCTV4-å›½é™…", "CCTV04"],
           "CCTV5": ["CCTV5", "CCTV-5", "CCTV5ä½“è‚²", "CCTV5é«˜æ¸…", "CCTV5HD", "cctv5", "ä¸­å¤®5å°", "sCCTV5-ä½“è‚²", "CCTV05"],
           "CCTV5+": ["CCTV5+", "CCTV-5+", "CCTV5+ä½“è‚²èµ›äº‹", "CCTV5+é«˜æ¸…", "CCTV5+HD", "cctv5+", "CCTV5plus"],
           "CCTV6": ["CCTV6", "CCTV-6", "CCTV6ç”µå½±", "CCTV6é«˜æ¸…", "CCTV6HD", "cctv6", "ä¸­å¤®6å°", "sCCTV6-ç”µå½±", "CCTV06"],
           "CCTV7": ["CCTV7", "CCTV-7", "CCTV7å†›äº‹", "CCTV7é«˜æ¸…", "CCTV7HD", "cctv7", "ä¸­å¤®7å°", "CCTV07"],
           "CCTV8": ["CCTV8", "CCTV-8", "CCTV8ç”µè§†å‰§", "CCTV8é«˜æ¸…", "CCTV8HD", "cctv8", "ä¸­å¤®8å°", "sCCTV8-ç”µè§†å‰§", "CCTV08"],
           "CCTV9": ["CCTV9", "CCTV-9", "CCTV9çºªå½•", "CCTV9é«˜æ¸…", "CCTV9HD", "cctv9", "ä¸­å¤®9å°", "sCCTV9-çºªå½•", "CCTV09"],
           "CCTV10": ["CCTV10", "CCTV-10", "CCTV10ç§‘æ•™", "CCTV10é«˜æ¸…", "CCTV10HD", "cctv10", "ä¸­å¤®10å°", "sCCTV10-ç§‘æ•™"],
           "CCTV11": ["CCTV11", "CCTV-11", "CCTV11æˆæ›²", "CCTV11é«˜æ¸…", "CCTV11HD", "cctv11", "ä¸­å¤®11å°", "sCCTV11-æˆæ›²"],
           "CCTV12": ["CCTV12", "CCTV-12", "CCTV12ç¤¾ä¼šä¸Žæ³•", "CCTV12é«˜æ¸…", "CCTV12HD", "cctv12", "ä¸­å¤®12å°", "sCCTV12-ç¤¾ä¼šä¸Žæ³•"],
           "CCTV13": ["CCTV13", "CCTV-13", "CCTV13æ–°é—»", "CCTV13é«˜æ¸…", "CCTV13HD", "cctv13", "ä¸­å¤®13å°", "sCCTV13-æ–°é—»"],
           "CCTV14": ["CCTV14", "CCTV-14", "CCTV14å°‘å„¿", "CCTV14é«˜æ¸…", "CCTV14HD", "cctv14", "ä¸­å¤®14å°", "sCCTV14-å°‘å„¿"],
           "CCTV15": ["CCTV15", "CCTV-15", "CCTV15éŸ³ä¹", "CCTV15é«˜æ¸…", "CCTV15HD", "cctv15", "ä¸­å¤®15å°", "sCCTV15-éŸ³ä¹"],
           "CCTV16": ["CCTV16", "CCTV-16", "CCTV16å¥¥æž—åŒ¹å…‹", "CCTV16é«˜æ¸…", "CCTV16HD", "cctv16", "ä¸­å¤®16å°"],
           "CCTV17": ["CCTV17", "CCTV-17", "CCTV17å†œä¸šå†œæ‘", "CCTV17é«˜æ¸…", "CCTV17HD", "cctv17", "ä¸­å¤®17å°"],
           
           "æµ™æ±Ÿå«è§†": ["æµ™æ±Ÿå«è§†", "æµ™æ±Ÿå«è§†é«˜æ¸…"],
           "åŒ—äº¬å«è§†": ["åŒ—äº¬å«è§†", "åŒ—äº¬å«è§†HD", "åŒ—äº¬å«è§†é«˜æ¸…"],
           "æ¹–å—å«è§†": ["æ¹–å—å«è§†", "æ¹–å—ç”µè§†"],
           "æ±Ÿè‹å«è§†": ["æ±Ÿè‹å«è§†", "æ±Ÿè‹å«è§†HD", "æ±Ÿè‹å«è§†é«˜æ¸…"],
           "ä¸œæ–¹å«è§†": ["ä¸œæ–¹å«è§†", "ä¸Šæµ·å«è§†", "SBN"],
           "å®‰å¾½å«è§†": ["å®‰å¾½å«è§†", "å®‰å¾½å«è§†é«˜æ¸…"],
           "å±±ä¸œå«è§†": ["å±±ä¸œå«è§†", "å±±ä¸œé«˜æ¸…", "å±±ä¸œå«è§†é«˜æ¸…", "å±±ä¸œå«è§†HD"],
           "å¹¿ä¸œå«è§†": ["å¹¿ä¸œå«è§†", "å¹¿ä¸œå«è§†é«˜æ¸…"],
           "æ·±åœ³å«è§†": ["æ·±åœ³å«è§†", "æ·±åœ³å«è§†é«˜æ¸…", "æ·±åœ³"],
           "å¤©æ´¥å«è§†": ["å¤©æ´¥å«è§†"],
           "æ²³åŒ—å«è§†": ["æ²³åŒ—å«è§†"],
           "å±±è¥¿å«è§†": ["å±±è¥¿å«è§†"],
           "å†…è’™å¤å«è§†": ["å†…è’™å¤å«è§†", "å†…è’™å¤", "å†…è’™å«è§†"],
           "è¾½å®å«è§†": ["è¾½å®å«è§†", "è¾½å®å«è§†HD"],
           "å‰æž—å«è§†": ["å‰æž—å«è§†"],
           "é»‘é¾™æ±Ÿå«è§†": ["é»‘é¾™æ±Ÿå«è§†"],
           "ä¸Šæµ·å«è§†": ["ä¸Šæµ·å«è§†", "ä¸œæ–¹å«è§†"],
           "ç¦å»ºä¸œå—å«è§†": ["ä¸œå—å«è§†", "ç¦å»ºä¸œå—"],
           "æ±Ÿè¥¿å«è§†": ["æ±Ÿè¥¿å«è§†"],
           "æ²³å—å«è§†": ["æ²³å—å«è§†"],
           "æ¹–åŒ—å«è§†": ["æ¹–åŒ—å«è§†"],
           "å¹¿è¥¿å«è§†": ["å¹¿è¥¿å«è§†"],
           "æµ·å—å«è§†": ["æµ·å—å«è§†", "æ—…æ¸¸å«è§†", "æµ·å—å«è§†HD"],
           "é‡åº†å«è§†": ["é‡åº†å«è§†"],
           "å››å·å«è§†": ["å››å·å«è§†", "å››å·å«è§†é«˜æ¸…"],
           "è´µå·žå«è§†": ["è´µå·žå«è§†"],
           "äº‘å—å«è§†": ["äº‘å—å«è§†"],
           "è¥¿è—å«è§†": ["è¥¿è—å«è§†", "XZTV2"],
           "é™•è¥¿å«è§†": ["é™•è¥¿å«è§†"],
           "ç”˜è‚ƒå«è§†": ["ç”˜è‚ƒå«è§†"],
           "é’æµ·å«è§†": ["é’æµ·å«è§†"],
           "å®å¤å«è§†": ["å®å¤å«è§†"],
           "æ–°ç–†å«è§†": ["æ–°ç–†å«è§†", "æ–°ç–†1"],
           
           "å‡¤å‡°å«è§†ä¸­æ–‡å°": ["å‡¤å‡°å«è§†ä¸­æ–‡å°", "å‡¤å‡°ä¸­æ–‡", "å‡¤å‡°å«è§†"],
           "å‡¤å‡°å«è§†èµ„è®¯å°": ["å‡¤å‡°å«è§†èµ„è®¯å°", "å‡¤å‡°èµ„è®¯", "å‡¤å‡°å’¨è¯¢"],
           "å‡¤å‡°å«è§†é¦™æ¸¯å°": ["å‡¤å‡°å«è§†é¦™æ¸¯å°", "å‡¤å‡°é¦™æ¸¯"],
           "å‡¤å‡°å«è§†ç”µå½±å°": ["å‡¤å‡°å«è§†ç”µå½±å°", "å‡¤å‡°ç”µå½±", "é³³å‡°è¡›è¦–é›»å½±å°"],
       }
       
       # å›¾æ ‡æ–‡ä»¶è·¯å¾„
       LOGO_FILE = "Hotel/logo.txt"
       
       # ===============================
       # å·¥å…·å‡½æ•°
       # ===============================
       
       def get_random_headers():
           """èŽ·å–éšæœºUser-Agentçš„headers"""
           return {
               "User-Agent": random.choice(USER_AGENTS),
               "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
               "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
               "Accept-Encoding": "gzip, deflate, br",
               "Connection": "keep-alive",
               "Upgrade-Insecure-Requests": "1"
           }
       
       def get_api_headers():
           """èŽ·å–APIè¯·æ±‚çš„headers"""
           auth = get_fofa_auth()
           if auth:
               return {
                   "User-Agent": random.choice(USER_AGENTS),
                   "Authorization": f"Basic {auth}",
                   "Content-Type": "application/json"
               }
           else:
               # å¦‚æžœæ²¡æœ‰APIè®¤è¯ï¼Œä½¿ç”¨Cookie
               cookie = get_fofa_cookie()
               headers = get_random_headers()
               headers["Cookie"] = cookie
               return headers
       
       def get_isp(ip):
           """IPè¿è¥å•†åˆ¤æ–­"""
           telecom_pattern = r"^(1\.|14\.|27\.|36\.|39\.|42\.|49\.|58\.|60\.|101\.|106\.|110\.|111\.|112\.|113\.|114\.|115\.|116\.|117\.|118\.|119\.|120\.|121\.|122\.|123\.|124\.|125\.|126\.|171\.|175\.|182\.|183\.|202\.|203\.|210\.|211\.|218\.|219\.|220\.|221\.|222\.)"
           unicom_pattern = r"^(42\.1[0-9]{0,2}|43\.|58\.|59\.|60\.|61\.|110\.|111\.|112\.|113\.|114\.|115\.|116\.|117\.|118\.|119\.|120\.|121\.|122\.|123\.|124\.|125\.|126\.|171\.8[0-9]|171\.9[0-9]|171\.1[0-9]{2}|175\.|182\.|183\.|210\.|211\.|218\.|219\.|220\.|221\.|222\.)"
           mobile_pattern = r"^(36\.|37\.|38\.|39\.1[0-9]{0,2}|42\.2|42\.3|47\.|106\.|111\.|112\.|113\.|114\.|115\.|116\.|117\.|118\.|119\.|120\.|121\.|122\.|123\.|124\.|125\.|126\.|134\.|135\.|136\.|137\.|138\.|139\.|150\.|151\.|152\.|157\.|158\.|159\.|170\.|178\.|182\.|183\.|184\.|187\.|188\.|189\.)"
           
           if re.match(telecom_pattern, ip):
               return "ç”µä¿¡"
           elif re.match(unicom_pattern, ip):
               return "è”é€š"
           elif re.match(mobile_pattern, ip):
               return "ç§»åŠ¨"
           else:
               return "æœªçŸ¥"
       
       def get_ip_info(ip_port):
           """èŽ·å–IPåœ°ç†ä¿¡æ¯"""
           try:
               ip = ip_port.split(":")[0]
               
               # ä½¿ç”¨IP-APIæŸ¥è¯¢
               try:
                   response = requests.get(f"http://ip-api.com/json/{ip}?lang=zh-CN", timeout=5)
                   if response.status_code == 200:
                       data = response.json()
                       if data.get("status") == "success":
                           province = data.get("regionName", "æœªçŸ¥")
                           isp = get_isp(ip)
                           return province, isp, ip_port
               except:
                   pass
               
               return "æœªçŸ¥", "æœªçŸ¥", ip_port
               
           except Exception as e:
               return "æœªçŸ¥", "æœªçŸ¥", ip_port
       
       def parse_ip_line(line):
           """è§£æžIPè¡Œï¼Œæ”¯æŒæ ¼å¼ï¼šip:port$è¿è¥å•†å·²å­˜æ´»nå¤©"""
           line = line.strip()
           if not line or line.startswith('#'):
               return None, None, 0, None, None
           
           # åŒ¹é…IP:ç«¯å£æ ¼å¼
           ip_match = re.match(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d{1,5})', line)
           if not ip_match:
               return None, None, 0, None, None
           
           ip_port = ip_match.group(1)
           
           # å°è¯•è§£æžå­˜æ´»å¤©æ•°
           days_match = re.search(r'å·²å­˜æ´»(\d+)å¤©', line)
           days = int(days_match.group(1)) if days_match else 0
           
           # å°è¯•è§£æžè¿è¥å•†
           isp_match = re.search(r'\$([^$]+?)å·²å­˜æ´»', line)
           isp = isp_match.group(1).strip() if isp_match else ""
           
           # å°è¯•è§£æžæœ€åŽæ›´æ–°æ—¥æœŸ
           date_match = re.search(r'æœ€åŽæ›´æ–°:(\d{4}-\d{2}-\d{2})', line)
           last_update = date_match.group(1) if date_match else None
           
           # å°è¯•è§£æžé€Ÿåº¦
           speed_match = re.search(r'#é€Ÿåº¦:([\d.]+)MB/s', line)
           speed = float(speed_match.group(1)) if speed_match else 0.0
           
           return ip_port, isp, days, last_update, speed
       
       def read_existing_ips(filepath):
           """è¯»å–çŽ°æœ‰æ–‡ä»¶å†…å®¹å¹¶è§£æž"""
           existing_ips = {}  # ip_port: (days, isp, last_update, speed)
           if os.path.exists(filepath):
               try:
                   with open(filepath, 'r', encoding='utf-8') as f:
                       for line in f:
                           ip_port, isp, days, last_update, speed = parse_ip_line(line)
                           if ip_port:
                               existing_ips[ip_port] = (days, isp, last_update, speed)
               except Exception as e:
                   print(f"âŒ è¯»å–æ–‡ä»¶ {filepath} å¤±è´¥: {e}")
           
           return existing_ips
       
       def encode_query(query):
           """ç¼–ç æŸ¥è¯¢å­—ç¬¦ä¸²ä¸ºbase64"""
           return base64.b64encode(query.encode()).decode()
       
       def generate_fofa_urls():
           """ç”ŸæˆFOFAæœç´¢URL"""
           urls = []
           pages = 1
           page_size = 20
           
           for query in SEARCH_QUERIES:
               encoded_query = encode_query(query)
               for page in range(1, pages + 1):
                   url = f"https://gh-proxy.com/https://fofa.info/result?qbase64={encoded_query}&page={page}&page_size={page_size}"
                   urls.append(url)
           
           return urls
       
       # ===============================
       # FOFAçˆ¬å–å‡½æ•°
       # ===============================
       
       def crawl_fofa_with_api():
           """ä½¿ç”¨FOFA APIçˆ¬å–æ•°æ®"""
           all_ips = set()
           timeout = 10
           max_workers = 5
           
           print(f"ðŸ” å¼€å§‹ä½¿ç”¨FOFA APIçˆ¬å–ï¼Œå…± {len(SEARCH_QUERIES)} ä¸ªæœç´¢æŸ¥è¯¢")
           
           def search_single_query(query):
               """å•ä¸ªæŸ¥è¯¢çš„æœç´¢å‡½æ•°"""
               try:
                   time.sleep(random.uniform(1, 3))
                   
                   encoded_query = encode_query(query)
                   url = f"https://fofa.info/api/v1/search/all?key={encoded_query}&page=1&size=50&fields=ip,port"
                   
                   headers = get_api_headers()
                   response = requests.get(url, headers=headers, timeout=timeout)
                   
                   if response.status_code == 401:
                       print(f"âŒ APIè®¤è¯å¤±è´¥ï¼Œå°†å°è¯•ä½¿ç”¨Cookieæ–¹å¼")
                       return set()
                   elif response.status_code == 402:
                       print(f"âŒ è´¦æˆ·ä½™é¢ä¸è¶³ï¼Œå°†å°è¯•ä½¿ç”¨Cookieæ–¹å¼")
                       return set()
                   elif response.status_code == 420:
                       print(f"âŒ è¯·æ±‚è¿‡äºŽé¢‘ç¹ï¼Œè¯·ç¨åŽé‡è¯•")
                       return set()
                   elif response.status_code != 200:
                       print(f"âŒ APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                       return set()
                   
                   data = response.json()
                   if not data.get("error"):
                       results = data.get("results", [])
                       page_ips = set()
                       
                       for result in results:
                           if len(result) >= 2:
                               ip = result[0]
                               port = result[1]
                               if ip and port:
                                   ip_match = re.match(r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}', ip)
                                   if ip_match:
                                       ip_parts = ip_match.group().split('.')
                                       if all(0 <= int(part) <= 255 for part in ip_parts):
                                           if 1 <= int(port) <= 65535:
                                               ip_port = f"{ip}:{port}"
                                               page_ips.add(ip_port)
                                               print(f"âœ… æ‰¾åˆ°IP: {ip_port}")
                       
                       print(f"âœ… æŸ¥è¯¢ '{query}' èŽ·å–åˆ° {len(page_ips)} ä¸ªIP")
                       return page_ips
                   else:
                       print(f"âŒ æŸ¥è¯¢ '{query}' å¤±è´¥: {data.get('errmsg', 'æœªçŸ¥é”™è¯¯')}")
                       return set()
                       
               except Exception as e:
                   print(f"âŒ æŸ¥è¯¢ '{query}' å¤±è´¥: {str(e)[:100]}")
                   return set()
           
           # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæœç´¢
           with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
               futures = {executor.submit(search_single_query, query): query for query in SEARCH_QUERIES}
               
               for future in concurrent.futures.as_completed(futures):
                   query = futures[future]
                   try:
                       page_ips = future.result()
                       all_ips.update(page_ips)
                       print(f"ðŸ“Š å½“å‰IPæ€»æ•°: {len(all_ips)}")
                   except Exception as e:
                       print(f"âŒ å¤„ç†æŸ¥è¯¢ '{query}' æ—¶å‘ç”Ÿé”™è¯¯: {e}")
           
           print(f"ðŸŽ¯ FOFA APIçˆ¬å–å®Œæˆï¼Œæ€»å…±èŽ·å–åˆ° {len(all_ips)} ä¸ªæœ‰æ•ˆIP")
           return list(all_ips)
       
       def crawl_fofa_with_cookie():
           """ä½¿ç”¨Cookieçˆ¬å–FOFAæ•°æ®"""
           urls = generate_fofa_urls()
           all_ips = set()
           
           print(f"ðŸ” å¼€å§‹ä½¿ç”¨Cookieçˆ¬å–FOFAï¼Œå…± {len(urls)} ä¸ªæœç´¢é¡µé¢")
           
           for i, url in enumerate(urls, 1):
               print(f"ðŸ“¡ æ­£åœ¨çˆ¬å–ç¬¬ {i}/{len(urls)} é¡µ...")
               
               try:
                   time.sleep(random.uniform(3, 8))
                   
                   headers = get_api_headers()  # ä½¿ç”¨åŒ…å«Cookieçš„headers
                   response = requests.get(url, headers=headers, timeout=15)
                   
                   if response.status_code != 200:
                       print(f"âŒ ç¬¬ {i} é¡µè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                       continue
                   
                   page_ips = set()
                   
                   # æ–¹æ³•1: ç›´æŽ¥æœç´¢IP:ç«¯å£æ ¼å¼
                   ip_matches = re.findall(r'\b(?:\d{1,3}\.){3}\d{1,3}:\d{1,5}\b', response.text)
                   for match in ip_matches:
                       ip_match = re.match(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}):(\d{1,5})', match)
                       if ip_match:
                           ip_parts = ip_match.group(1).split('.')
                           if all(0 <= int(part) <= 255 for part in ip_parts):
                               port = int(ip_match.group(2))
                               if 1 <= port <= 65535:
                                   page_ips.add(match)
                                   print(f"âœ… æ‰¾åˆ°IP: {match}")
                   
                   # æ–¹æ³•2: æœç´¢hrefä¸­çš„IP
                   href_matches = re.findall(r'href="[^"]*?//(\d+\.\d+\.\d+\.\d+:\d+)', response.text)
                   for match in href_matches:
                       ip_match = re.match(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}):(\d{1,5})', match)
                       if ip_match:
                           ip_parts = ip_match.group(1).split('.')
                           if all(0 <= int(part) <= 255 for part in ip_parts):
                               port = int(ip_match.group(2))
                               if 1 <= port <= 65535:
                                   page_ips.add(match)
                                   print(f"âœ… æ‰¾åˆ°IP: {match}")
                   
                   all_ips.update(page_ips)
                   print(f"âœ… ç¬¬ {i} é¡µèŽ·å–åˆ° {len(page_ips)} ä¸ªIPï¼Œå½“å‰æ€»æ•° {len(all_ips)}")
                   
               except Exception as e:
                   print(f"âŒ ç¬¬ {i} é¡µçˆ¬å–å¤±è´¥: {str(e)[:100]}")
           
           print(f"ðŸŽ¯ Cookieçˆ¬å–å®Œæˆï¼Œæ€»å…±èŽ·å–åˆ° {len(all_ips)} ä¸ªæœ‰æ•ˆIP")
           return list(all_ips)
       
       def crawl_fofa_ips():
           """çˆ¬å–FOFA IPï¼Œä¼˜å…ˆä½¿ç”¨APIï¼Œå¤±è´¥åˆ™ä½¿ç”¨Cookie"""
           print("ðŸš€ å¼€å§‹çˆ¬å–FOFA IP...")
           
           # é¦–å…ˆå°è¯•ä½¿ç”¨API
           api_ips = crawl_fofa_with_api()
           if api_ips:
               print("âœ… APIæ–¹å¼çˆ¬å–æˆåŠŸ")
               return api_ips
           
           print("âš ï¸ APIæ–¹å¼å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨Cookieæ–¹å¼...")
           
           # å¦‚æžœAPIå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨Cookie
           cookie_ips = crawl_fofa_with_cookie()
           if cookie_ips:
               print("âœ… Cookieæ–¹å¼çˆ¬å–æˆåŠŸ")
               return cookie_ips
           
           print("âŒ æ‰€æœ‰çˆ¬å–æ–¹å¼éƒ½å¤±è´¥")
           return []
       
       # ===============================
       # IPå¯ç”¨æ€§éªŒè¯å’Œæµ‹é€Ÿå‡½æ•°
       # ===============================
       
       def test_ip_availability(ip_port):
           """æµ‹è¯•IPå¯ç”¨æ€§"""
           try:
               json_url = f"http://{ip_port}/iptv/live/1000.json?key=txiptv"
               response = requests.get(json_url, timeout=5)
               
               if response.status_code == 200:
                   try:
                       data = response.json()
                       if data.get("code") == 0 and "data" in data:
                           return True, data
                   except:
                       pass
               return False, None
           except:
               return False, None
       
       def get_province_tv_url(ip_port, json_data, province_name):
           """èŽ·å–çœä»½å«è§†URL"""
           try:
               tv_name = None
               for category, channels in CHANNEL_CATEGORIES.items():
                   for channel in channels:
                       if province_name in channel and "å«è§†" in channel:
                           tv_name = channel
                           break
                   if tv_name:
                       break
               
               if not tv_name:
                   tv_name = f"{province_name}å«è§†"
               
               for channel in json_data.get("data", []):
                   channel_name = channel.get("name", "")
                   if tv_name in channel_name:
                       url = channel.get("url", "")
                       if url:
                           if url.startswith("/"):
                               return f"http://{ip_port}{url}"
                           else:
                               return f"http://{ip_port}/{url}"
               return None
           except:
               return None
       
       def test_channel_speed_simple(channel_url, max_attempts=2):
           """ç®€åŒ–ç‰ˆæµ‹é€Ÿå‡½æ•°"""
           best_speed = 0.0
           
           for attempt in range(max_attempts):
               try:
                   start_time = time.time()
                   response = requests.get(channel_url, timeout=5, stream=True)
                   
                   if response.status_code == 200:
                       content_length = 0
                       chunk_size = 1024 * 1024
                       for chunk in response.iter_content(chunk_size=chunk_size):
                           if chunk:
                               content_length += len(chunk)
                               if content_length >= chunk_size:
                                   break
                       
                       resp_time = time.time() - start_time
                       
                       if content_length > 0 and resp_time > 0:
                           speed = content_length / resp_time / 1024 / 1024
                           if speed > best_speed:
                               best_speed = speed
                           
                           if speed > SPEED_THRESHOLD:
                               break
                               
               except Exception:
                   continue
           
           return best_speed
       
       def test_single_ip_simple(ip_port, province_name):
           """ç®€åŒ–ç‰ˆIPæµ‹è¯•"""
           try:
               is_available, json_data = test_ip_availability(ip_port)
               if not is_available:
                   return 0.0, False
               
               channel_url = get_province_tv_url(ip_port, json_data, province_name)
               if not channel_url:
                   return 0.0, False
               
               speed = test_channel_speed_simple(channel_url)
               return speed, speed > SPEED_THRESHOLD
               
           except Exception:
               return 0.0, False
       
       def speed_test_ips_simple(ip_list, province_name):
           """ç®€åŒ–ç‰ˆå¤šçº¿ç¨‹æµ‹é€Ÿ"""
           results = []
           max_workers = 5
           
           def test_ip(ip_info):
               ip_port = ip_info[0]
               speed, is_usable = test_single_ip_simple(ip_port, province_name)
               
               if is_usable:
                   results.append((ip_info[0], ip_info[1], ip_info[2], speed))
                   print(f"âœ… {ip_port}: {speed:.3f} MB/s")
               else:
                   print(f"âŒ {ip_port}: {speed:.3f} MB/s")
           
           with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
               executor.map(test_ip, ip_list)
           
           results.sort(key=lambda x: x[3], reverse=True)
           return results
       
       # ===============================
       # æ–‡ä»¶ç®¡ç†å’Œæ›´æ–°å‡½æ•°
       # ===============================
       
       def calculate_days_between(date_str1, date_str2):
           """è®¡ç®—ä¸¤ä¸ªæ—¥æœŸå­—ç¬¦ä¸²ä¹‹é—´çš„å¤©æ•°å·®"""
           try:
               date1 = datetime.strptime(date_str1, "%Y-%m-%d")
               date2 = datetime.strptime(date_str2, "%Y-%m-%d")
               return (date2 - date1).days
           except:
               return 0
       
       def update_ip_file(filepath, new_usable_ips):
           """æ›´æ–°IPæ–‡ä»¶"""
           try:
               existing_ips = read_existing_ips(filepath)
               current_date = datetime.now().strftime("%Y-%m-%d")
               
               updated_ips = {}
               for ip_port, (days, isp, last_update, old_speed) in existing_ips.items():
                   is_still_usable = any(ip[0] == ip_port for ip in new_usable_ips)
                   
                   if is_still_usable:
                       if not isp:
                           ip = ip_port.split(":")[0]
                           isp = get_isp(ip)
                       
                       if last_update:
                           days_diff = calculate_days_between(last_update, current_date)
                           if days_diff > 0:
                               new_days = days + days_diff
                           else:
                               new_days = days
                       else:
                           new_days = 1
                       
                       new_speed = old_speed
                       for ip_info in new_usable_ips:
                           if ip_info[0] == ip_port:
                               new_speed = ip_info[3]
                               break
                       
                       updated_ips[ip_port] = (new_days, isp, current_date, new_speed)
                   elif days > 0:
                       updated_ips[ip_port] = (days, isp, last_update, old_speed)
               
               for ip_info in new_usable_ips:
                   ip_port, isp, old_days, speed = ip_info
                   if ip_port not in updated_ips:
                       if not isp:
                           ip = ip_port.split(":")[0]
                           isp = get_isp(ip)
                       updated_ips[ip_port] = (1, isp, current_date, speed)
               
               if not updated_ips:
                   if os.path.exists(filepath):
                       os.remove(filepath)
                   print(f"ðŸ—‘ï¸ åˆ é™¤ç©ºæ–‡ä»¶: {os.path.basename(filepath)}")
                   return
               
               with open(filepath, 'w', encoding='utf-8') as f:
                   f.write(f"# æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                   f.write(f"# æµ‹é€Ÿé˜ˆå€¼: {SPEED_THRESHOLD} MB/s\n")
                   f.write("# æ ¼å¼: IP:ç«¯å£$è¿è¥å•†å·²å­˜æ´»nå¤©#æœ€åŽæ›´æ–°:YYYY-MM-DD#é€Ÿåº¦\n")
                   f.write("=" * 50 + "\n")
                   
                   sorted_ips = sorted(updated_ips.items(), key=lambda x: x[1][0], reverse=True)
                   
                   for ip_port, (days, isp, last_update, speed) in sorted_ips:
                       speed_info = f"#é€Ÿåº¦:{speed:.3f}MB/s" if speed > 0 else ""
                       f.write(f"{ip_port}${isp}å·²å­˜æ´»{days}å¤©#æœ€åŽæ›´æ–°:{last_update}{speed_info}\n")
               
               print(f"ðŸ’¾ å·²æ›´æ–° {os.path.basename(filepath)}ï¼Œæœ‰æ•ˆIP: {len(updated_ips)} ä¸ª")
               
           except Exception as e:
               print(f"âŒ æ›´æ–°æ–‡ä»¶ {filepath} å¤±è´¥: {e}")
       
       def validate_existing_ips():
           """éªŒè¯çŽ°æœ‰IPæ–‡ä»¶ä¸­çš„IP"""
           print("ðŸ” å¼€å§‹éªŒè¯çŽ°æœ‰IPæ–‡ä»¶...")
           
           for filename in os.listdir(IP_DIR):
               if filename.endswith('.txt') and filename != "ip_summary.txt":
                   filepath = os.path.join(IP_DIR, filename)
                   
                   match = re.match(r'(.+?)(ç”µä¿¡|è”é€š|ç§»åŠ¨|æœªçŸ¥)\.txt', filename)
                   if not match:
                       continue
                       
                   province = match.group(1)
                   isp = match.group(2)
                   
                   print(f"ðŸ“‹ éªŒè¯æ–‡ä»¶: {filename} (çœä»½: {province}, è¿è¥å•†: {isp})")
                   
                   existing_ips = read_existing_ips(filepath)
                   if not existing_ips:
                       print(f"âš ï¸ æ–‡ä»¶ {filename} ä¸ºç©ºï¼Œè·³è¿‡éªŒè¯")
                       continue
                   
                   ip_list = []
                   for ip_port, (days, isp_val, last_update, speed) in existing_ips.items():
                       ip_list.append((ip_port, isp_val, days))
                   
                   usable_ips = speed_test_ips_simple(ip_list, province)
                   update_ip_file(filepath, usable_ips)
           
           print("âœ… çŽ°æœ‰IPéªŒè¯å®Œæˆ")
       
       def process_new_ips(new_ips):
           """å¤„ç†æ–°èŽ·å–çš„IP"""
           if not new_ips:
               print("âš ï¸ æ²¡æœ‰èŽ·å–åˆ°æ–°IP")
               return
           
           print(f"ðŸ”§ å¼€å§‹å¤„ç† {len(new_ips)} ä¸ªæ–°IP...")
           
           province_isp_dict = {}
           with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
               future_to_ip = {executor.submit(get_ip_info, ip): ip for ip in new_ips}
               
               for future in concurrent.futures.as_completed(future_to_ip):
                   province, isp, ip_port = future.result()
                   
                   if not province or province == "æœªçŸ¥":
                       province = "å…¶ä»–"
                   else:
                       province = province.replace("çœ", "").replace("å¸‚", "").replace("è‡ªæ²»åŒº", "").replace("ç‰¹åˆ«è¡Œæ”¿åŒº", "").strip()
                       if not province:
                           province = "å…¶ä»–"
                   
                   if not isp or isp == "æœªçŸ¥":
                       ip = ip_port.split(":")[0]
                       isp = get_isp(ip)
                   
                   fname = f"{province}{isp}.txt"
                   province_isp_dict.setdefault(fname, []).append((ip_port, isp, 0))
           
           for fname, ip_list in province_isp_dict.items():
               filepath = os.path.join(IP_DIR, fname)
               
               match = re.match(r'(.+?)(ç”µä¿¡|è”é€š|ç§»åŠ¨|æœªçŸ¥)\.txt', fname)
               province = match.group(1) if match else "å…¶ä»–"
               
               print(f"ðŸ§ª æµ‹è¯• {fname} ä¸­çš„ {len(ip_list)} ä¸ªæ–°IP...")
               usable_ips = speed_test_ips_simple(ip_list, province)
               
               if usable_ips:
                   update_ip_file(filepath, usable_ips)
               else:
                   print(f"âš ï¸ {fname} ä¸­æ²¡æœ‰å¯ç”¨çš„æ–°IP")
           
           print("âœ… æ–°IPå¤„ç†å®Œæˆ")
       
       # ===============================
       # é¢‘é“æ–‡ä»¶ç”ŸæˆåŠŸèƒ½
       # ===============================
       
       def remove_special_symbols(text):
           """ç§»é™¤é¢‘é“åç§°ä¸­çš„ç‰¹æ®Šç¬¦å·"""
           if not text:
               return ""
           
           for symbol in SPECIAL_SYMBOLS:
               text = text.replace(symbol, "")
           text = re.sub(r'\s+', '', text)
           return text.strip()
       
       def load_channel_logos():
           """åŠ è½½é¢‘é“å›¾æ ‡æ˜ å°„"""
           channel_logos = {}
           if os.path.exists(LOGO_FILE):
               try:
                   with open(LOGO_FILE, 'r', encoding='utf-8') as f:
                       for line in f:
                           line = line.strip()
                           if line and ',' in line:
                               parts = line.split(',', 1)
                               if len(parts) == 2:
                                   channel_name = parts[0].strip()
                                   logo_url = parts[1].strip()
                                   channel_logos[channel_name] = logo_url
                   print(f"âœ… å·²åŠ è½½ {len(channel_logos)} ä¸ªé¢‘é“å›¾æ ‡")
               except Exception as e:
                   print(f"âŒ åŠ è½½é¢‘é“å›¾æ ‡æ–‡ä»¶å¤±è´¥: {e}")
           else:
               print(f"âš ï¸ é¢‘é“å›¾æ ‡æ–‡ä»¶ä¸å­˜åœ¨: {LOGO_FILE}")
           return channel_logos
       
       def map_channel_name(raw_name):
           """å°†åŽŸå§‹é¢‘é“åç§°æ˜ å°„åˆ°æ ‡å‡†åç§°"""
           if not raw_name:
               return "æœªçŸ¥é¢‘é“"
           
           clean_name = remove_special_symbols(raw_name)
           
           for standard_name, variants in CHANNEL_MAPPING.items():
               for variant in variants:
                   if clean_name == remove_special_symbols(variant):
                       return standard_name
           
           for standard_name, variants in CHANNEL_MAPPING.items():
               for variant in variants:
                   if standard_name in clean_name or clean_name in standard_name:
                       return standard_name
                   if any(keyword in clean_name for keyword in ["CCTV", "å«è§†", "TV"]):
                       for v in variants:
                           if any(keyword in clean_name for keyword in ["CCTV", "å«è§†"]):
                               return standard_name
           
           return clean_name
       
       def categorize_channel(channel_name):
           """å°†é¢‘é“åˆ†ç±»"""
           for category, channels in CHANNEL_CATEGORIES.items():
               if channel_name in channels:
                   return category
           return "å…¶ä»–é¢‘é“"
       
       def get_channel_logo(channel_name, logo_dict):
           """èŽ·å–é¢‘é“å›¾æ ‡URL"""
           if channel_name in logo_dict:
               return logo_dict[channel_name]
           
           clean_name = remove_special_symbols(channel_name)
           for logo_channel, logo_url in logo_dict.items():
               if clean_name == remove_special_symbols(logo_channel):
                   return logo_url
           
           return ""
       
       def collect_all_channels():
           """æ”¶é›†æ‰€æœ‰IPæ–‡ä»¶ä¸­çš„é¢‘é“ä¿¡æ¯"""
           all_channels = {}
           logo_dict = load_channel_logos()
           
           print("ðŸ“º å¼€å§‹æ”¶é›†æ‰€æœ‰é¢‘é“ä¿¡æ¯...")
           
           for filename in os.listdir(IP_DIR):
               if filename.endswith('.txt') and filename != "ip_summary.txt":
                   filepath = os.path.join(IP_DIR, filename)
                   
                   existing_ips = read_existing_ips(filepath)
                   
                   for ip_port, (days, isp, last_update, speed) in existing_ips.items():
                       if days > 0:
                           try:
                               is_available, json_data = test_ip_availability(ip_port)
                               if is_available and json_data:
                                   for channel in json_data.get("data", []):
                                       raw_name = channel.get("name", "")
                                       if raw_name:
                                           std_name = map_channel_name(raw_name)
                                           category = categorize_channel(std_name)
                                           logo = get_channel_logo(std_name, logo_dict)
                                           
                                           url = channel.get("url", "")
                                           if url:
                                               if url.startswith("/"):
                                                   play_url = f"http://{ip_port}{url}"
                                               else:
                                                   play_url = f"http://{ip_port}/{url}"
                                               
                                               channel_key = f"{std_name}|{play_url}"
                                               if channel_key not in all_channels:
                                                   all_channels[channel_key] = {
                                                       "name": std_name,
                                                       "url": play_url,
                                                       "logo": logo,
                                                       "category": category,
                                                       "ip": ip_port,
                                                       "speed": speed
                                                   }
                           except Exception as e:
                               print(f"âŒ å¤„ç†IP {ip_port} çš„é¢‘é“ä¿¡æ¯å¤±è´¥: {e}")
           
           print(f"âœ… å…±æ”¶é›†åˆ° {len(all_channels)} ä¸ªé¢‘é“")
           return all_channels
       
       def generate_iptv_txt(channels_dict):
           """ç”ŸæˆIPTV.txtæ–‡ä»¶"""
           output_file = os.path.join(CHANNEL_DIR, "IPTV.txt")
           
           categorized_channels = {}
           for channel_info in channels_dict.values():
               category = channel_info["category"]
               categorized_channels.setdefault(category, []).append(channel_info)
           
           sorted_categories = []
           for cat in CHANNEL_CATEGORIES.keys():
               if cat in categorized_channels:
                   sorted_categories.append(cat)
           
           if "å…¶ä»–é¢‘é“" in categorized_channels:
               sorted_categories.append("å…¶ä»–é¢‘é“")
           
           try:
               with open(output_file, 'w', encoding='utf-8', errors='ignore') as f:
                   update_time = datetime.now().strftime('%Y/%m/%d %H:%Mæ›´æ–°')
                   f.write(f"{update_time},#genre#\n\n")
                   
                   for category in sorted_categories:
                       f.write(f"{category},#genre#\n")
                       channels = categorized_channels[category]
                       
                       channel_groups = {}
                       for channel in channels:
                           channel_name = channel["name"]
                           if channel_name not in channel_groups:
                               channel_groups[channel_name] = []
                           channel_groups[channel_name].append(channel)
                       
                       for channel_name, channel_list in channel_groups.items():
                           channel_list.sort(key=lambda x: x["speed"], reverse=True)
                           
                           for channel in channel_list:
                               f.write(f"{channel['name']},{channel['url']}\n")
                       
                       f.write("\n")
               
               print(f"ðŸ’¾ å·²ç”ŸæˆIPTV.txtï¼Œå…± {len(channels_dict)} ä¸ªé¢‘é“ï¼Œ{len(sorted_categories)} ä¸ªåˆ†ç±»")
               return True
               
           except Exception as e:
               print(f"âŒ ç”ŸæˆIPTV.txtå¤±è´¥: {e}")
               return False
       
       def generate_iptv_m3u(channels_dict):
           """ç”ŸæˆIPTV.m3uæ–‡ä»¶"""
           output_file = os.path.join(CHANNEL_DIR, "IPTV.m3u")
           
           categorized_channels = {}
           for channel_info in channels_dict.values():
               category = channel_info["category"]
               categorized_channels.setdefault(category, []).append(channel_info)
           
           sorted_categories = []
           for cat in CHANNEL_CATEGORIES.keys():
               if cat in categorized_channels:
                   sorted_categories.append(cat)
           
           if "å…¶ä»–é¢‘é“" in categorized_channels:
               sorted_categories.append("å…¶ä»–é¢‘é“")
           
           try:
               with open(output_file, 'w', encoding='utf-8') as f:
                   f.write("#EXTM3U\n")
                   f.write('x-tvg-url=""\n')
                   
                   for category in sorted_categories:
                       channels = categorized_channels[category]
                       
                       channel_groups = {}
                       for channel in channels:
                           channel_name = channel["name"]
                           if channel_name not in channel_groups:
                               channel_groups[channel_name] = []
                           channel_groups[channel_name].append(channel)
                       
                       for channel_name, channel_list in channel_groups.items():
                           channel_list.sort(key=lambda x: x["speed"], reverse=True)
                           
                           for channel in channel_list:
                               logo_info = f' tvg-logo="{channel["logo"]}"' if channel["logo"] else ""
                               f.write(f'#EXTINF:-1 tvg-name="{channel["name"]}"{logo_info} group-title="{category}",{channel["name"]}\n')
                               f.write(f'{channel["url"]}\n')
               
               print(f"ðŸ’¾ å·²ç”ŸæˆIPTV.m3uï¼Œå…± {len(channels_dict)} ä¸ªé¢‘é“ï¼Œ{len(sorted_categories)} ä¸ªåˆ†ç±»")
               return True
               
           except Exception as e:
               print(f"âŒ ç”ŸæˆIPTV.m3uå¤±è´¥: {e}")
               return False
       
       def generate_channel_files():
           """ç”Ÿæˆé¢‘é“æ–‡ä»¶ï¼ˆIPTV.txtå’ŒIPTV.m3uï¼‰"""
           print("ðŸŽ¬ å¼€å§‹ç”Ÿæˆé¢‘é“æ–‡ä»¶...")
           
           all_channels = collect_all_channels()
           
           if not all_channels:
               print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„é¢‘é“")
               return False
           
           txt_success = generate_iptv_txt(all_channels)
           m3u_success = generate_iptv_m3u(all_channels)
           
           if txt_success and m3u_success:
               print("âœ… é¢‘é“æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")
               return True
           else:
               print("âŒ é¢‘é“æ–‡ä»¶ç”Ÿæˆå¤±è´¥")
               return False
       
       # ===============================
       # ä¸»å‡½æ•°
       # ===============================
       
       def main():
           """ä¸»å‡½æ•°"""
           print("=" * 60)
           print("ðŸŒ FOFA IPåœ°å€æŠ“å–ä¸ŽéªŒè¯å·¥å…·")
           print(f"ðŸ“ IPç›®å½•: {IP_DIR}")
           print(f"ðŸ“º é¢‘é“ç›®å½•: {CHANNEL_DIR}")
           print(f"âš¡ æµ‹é€Ÿé˜ˆå€¼: {SPEED_THRESHOLD} MB/s")
           print("=" * 60)
           
           # ç¬¬ä¸€é˜¶æ®µï¼šéªŒè¯çŽ°æœ‰IP
           validate_existing_ips()
           
           # ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨APIèŽ·å–æ–°IP
           print("\nðŸš€ å¼€å§‹ä½¿ç”¨FOFA APIèŽ·å–æ–°IP...")
           new_ips = crawl_fofa_with_api()
           
           if new_ips:
               process_new_ips(new_ips)
           else:
               print("âŒ æ²¡æœ‰èŽ·å–åˆ°æ–°IP")
               print("ðŸ’¡ å¯èƒ½çš„åŽŸå› ï¼š")
               print("  1. API KEYæˆ–é‚®ç®±é”™è¯¯")
               print("  2. è´¦æˆ·ä½™é¢ä¸è¶³")
               print("  3. è¯·æ±‚è¿‡äºŽé¢‘ç¹")
               print("  4. å°†ä½¿ç”¨çŽ°æœ‰IPæ–‡ä»¶ç”Ÿæˆé¢‘é“")
           
           # ç¬¬ä¸‰é˜¶æ®µï¼šç”Ÿæˆé¢‘é“æ–‡ä»¶
           print("\nðŸ“º å¼€å§‹ç”Ÿæˆé¢‘é“æ–‡ä»¶...")
           generate_channel_files()
           
           print("\n" + "=" * 60)
           print("ðŸŽ‰ ä»»åŠ¡å®Œæˆï¼")
           print("=" * 60)

        if __name__ == "__main__":
        # å®‰è£…ä¾èµ–: pip install requests eventlet configparser
        main()
        EOF
    - name: æäº¤æ›´æ–°
      run: |
        cd $GITHUB_WORKSPACE
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add .
        git commit -m "æ›´æ–°é…’åº—æºip"
        git push
